##  Aplicaci贸n Multi-LLM con Memoria

Una aplicaci贸n de Streamlit que demuestra el uso de m煤ltiples modelos de lenguaje (LLMs) con memoria compartida. Esta aplicaci贸n permite a los usuarios interactuar con diferentes LLMs mientras mantiene un contexto conversacional coherente.

### Caracter铆sticas

- **M煤ltiples LLMs**
  - GPT-4 para razonamiento complejo
  - Claude para an谩lisis detallado
  - Llama2 para procesamiento local
  
- **Memoria Compartida**
  - Historial de conversaci贸n persistente
  - Contexto compartido entre modelos
  - Recuperaci贸n de informaci贸n previa

- **Interfaz Intuitiva**
  - Selecci贸n de modelo sencilla
  - Visualizaci贸n del historial
  - Indicadores de estado claros

### C贸mo Empezar

1. Clona el repositorio
```bash
git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git
cd llm_apps_with_memory_tutorials/multi_llm_memory
```

2. Instala las dependencias
```bash
pip install -r requirements.txt
```

3. Configura las claves API
```bash
# Crea un archivo .env con:
OPENAI_API_KEY=tu_clave_api_aqu铆
ANTHROPIC_API_KEY=tu_clave_api_aqu铆
```

4. Ejecuta la aplicaci贸n
```bash
streamlit run multi_llm_memory.py
```

### C贸mo Funciona

1. **Selecci贸n de Modelo**
   - Elige entre GPT-4, Claude o Llama2
   - Cada modelo tiene sus fortalezas 煤nicas

2. **Interacci贸n**
   - Ingresa tu mensaje o pregunta
   - El modelo seleccionado responde
   - La conversaci贸n se guarda en memoria

3. **Memoria Compartida**
   - El historial persiste entre cambios de modelo
   - Los modelos pueden referenciar informaci贸n previa
   - Mantiene la coherencia conversacional