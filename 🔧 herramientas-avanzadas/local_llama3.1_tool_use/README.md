##  Uso de Herramientas con Llama3 Local
Esta aplicaci贸n Streamlit demuestra el llamado a funciones con el modelo Llama3 local usando Ollama. Permite a los usuarios interactuar con un asistente de IA que puede acceder a herramientas espec铆ficas basadas en la selecci贸n del usuario.

### Caracter铆sticas
- Utiliza el modelo Llama3 local a trav茅s de Ollama como LLM
- Integra YFinance para la obtenci贸n de datos burs谩tiles y SerpAPI para capacidades de b煤squeda web
- Selecci贸n din谩mica de herramientas a trav茅s de una barra lateral amigable
- Interfaz de chat en tiempo real con el asistente de IA

### C贸mo Empezar

1. Clonar el repositorio de GitHub

```bash
git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git
cd local-llama3-tool-use
```
2. Instalar las dependencias requeridas:

```bash
pip install -r requirements.txt
```

3. Obtener tu Clave API de OpenAI

- Configura tu clave API de SerpAPI: Exporta tu clave API de SerpAPI como una variable de entorno.
```bash
export SERPAPI_API_KEY=tu_clave_api_aqu铆
```

4. Ejecutar la Aplicaci贸n Streamlit
```bash
streamlit run llama3_tool_use.py
```

## 驴C贸mo Funciona?

1. **Selecci贸n de Herramientas:** Los usuarios pueden seleccionar qu茅 herramientas (YFinance y/o SerpAPI) quieren que el asistente use a trav茅s de casillas de verificaci贸n en la barra lateral.

2. **Inicializaci贸n del Asistente:** La aplicaci贸n inicializa o actualiza el asistente basado en las herramientas seleccionadas.

3. **Interfaz de Chat:** Los usuarios pueden hacer preguntas a trav茅s de una entrada de chat, y el asistente responde usando las herramientas habilitadas.

4. **Respuesta en Tiempo Real:** La respuesta del asistente se muestra en tiempo real, con un indicador de escritura.

5. **Visualizaci贸n de Uso de Herramientas:** La aplicaci贸n muestra qu茅 herramientas est谩n actualmente habilitadas en la barra lateral.